{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Copyright **`(c)`** 2022 Giovanni Squillero `<squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Lab 2: ES\n",
    "\n",
    "## Task\n",
    "\n",
    "Write agents able to play [*Nim*](https://en.wikipedia.org/wiki/Nim), with an arbitrary number of rows and an upper bound $k$ on the number of objects that can be removed in a turn (a.k.a., *subtraction game*).\n",
    "\n",
    "The goal of the game is to **avoid** taking the last object.\n",
    "\n",
    "* Task2.1: An agent using fixed rules based on *nim-sum* (i.e., an *expert system*)\n",
    "* Task2.2: An agent using evolved rules using ES\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Create the directory `lab2` inside the course repo \n",
    "* Put a `README.md` and your solution (all the files, code and auxiliary data if needed)\n",
    "\n",
    "## Notes\n",
    "\n",
    "* Working in group is not only allowed, but recommended (see: [Ubuntu](https://en.wikipedia.org/wiki/Ubuntu_philosophy) and [Cooperative Learning](https://files.eric.ed.gov/fulltext/EJ1096789.pdf)). Collaborations must be explicitly declared in the `README.md`.\n",
    "* [Yanking](https://www.emacswiki.org/emacs/KillingAndYanking) from the internet is allowed, but sources must be explicitly declared in the `README.md`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import logging\n",
    "from pprint import pprint, pformat\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *Nim* and *Nimply* classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        if row < 0 or row >= len(self._rows):\n",
    "            raise ValueError(\"Invalid row index.\")\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample (and silly) startegies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    \"\"\"A completely random move\"\"\"\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabriele(state: Nim) -> Nimply:\n",
    "    \"\"\"Pick always the maximum possible number of the lowest row\"\"\"\n",
    "    possible_moves = [(r, o) for r, c in enumerate(state.rows) for o in range(1, c + 1)]\n",
    "    return Nimply(*max(possible_moves, key=lambda m: (-m[0], m[1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive(state: Nim) -> Nimply:\n",
    "    \"\"\"A strategy that can adapt its parameters\"\"\"\n",
    "    genome = {\"love_small\": 0.5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "\n",
    "def analize(raw: Nim) -> dict:\n",
    "    cooked = dict()\n",
    "    cooked[\"possible_moves\"] = dict()\n",
    "    for ply in (Nimply(r, o) for r, c in enumerate(raw.rows) for o in range(1, c + 1)):\n",
    "        tmp = deepcopy(raw)\n",
    "        tmp.nimming(ply)\n",
    "        cooked[\"possible_moves\"][ply] = nim_sum(tmp)\n",
    "    return cooked\n",
    "\n",
    "\n",
    "def optimal(state: Nim) -> Nimply:\n",
    "    analysis = analize(state)\n",
    "    logging.debug(f\"analysis:\\n{pformat(analysis)}\")\n",
    "    spicy_moves = [ply for ply, ns in analysis[\"possible_moves\"].items() if ns != 0]\n",
    "    if not spicy_moves:\n",
    "        spicy_moves = list(analysis[\"possible_moves\"].keys())\n",
    "    ply = random.choice(spicy_moves)\n",
    "    return ply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversimplified match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7 9>\n",
      "INFO:root:ply: player 0 plays Nimply(row=3, num_objects=6)\n",
      "INFO:root:status: <1 3 5 1 9>\n",
      "INFO:root:ply: player 1 plays Nimply(row=1, num_objects=1)\n",
      "INFO:root:status: <1 2 5 1 9>\n",
      "INFO:root:ply: player 0 plays Nimply(row=0, num_objects=1)\n",
      "INFO:root:status: <0 2 5 1 9>\n",
      "INFO:root:ply: player 1 plays Nimply(row=1, num_objects=2)\n",
      "INFO:root:status: <0 0 5 1 9>\n",
      "INFO:root:ply: player 0 plays Nimply(row=2, num_objects=2)\n",
      "INFO:root:status: <0 0 3 1 9>\n",
      "INFO:root:ply: player 1 plays Nimply(row=3, num_objects=1)\n",
      "INFO:root:status: <0 0 3 0 9>\n",
      "INFO:root:ply: player 0 plays Nimply(row=4, num_objects=2)\n",
      "INFO:root:status: <0 0 3 0 7>\n",
      "INFO:root:ply: player 1 plays Nimply(row=2, num_objects=1)\n",
      "INFO:root:status: <0 0 2 0 7>\n",
      "INFO:root:ply: player 0 plays Nimply(row=4, num_objects=6)\n",
      "INFO:root:status: <0 0 2 0 1>\n",
      "INFO:root:ply: player 1 plays Nimply(row=2, num_objects=1)\n",
      "INFO:root:status: <0 0 1 0 1>\n",
      "INFO:root:ply: player 0 plays Nimply(row=4, num_objects=1)\n",
      "INFO:root:status: <0 0 1 0 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=2, num_objects=1)\n",
      "INFO:root:status: <0 0 0 0 0>\n",
      "INFO:root:status: Player 0 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "strategy = (optimal, pure_random)\n",
    "\n",
    "nim = Nim(5)\n",
    "logging.info(f\"init : {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    logging.info(f\"ply: player {player} plays {ply}\")\n",
    "    nim.nimming(ply)\n",
    "    logging.info(f\"status: {nim}\")\n",
    "    player = 1 - player\n",
    "logging.info(f\"status: Player {player} won!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see what happen when the two players have the same strategy : we will play 50 times and see the winning rates of each player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:score: [46, 54]\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "strategy = (pure_random, pure_random)\n",
    "\n",
    "score = [0, 0]\n",
    "for i in range(100):\n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    #logging.info(f\"status: Player {player} won!\")\n",
    "    score[player] += 1\n",
    "logging.info(f\"score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:score: [58, 42]\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "strategy = (optimal, optimal)\n",
    "\n",
    "score = [0, 0]\n",
    "for i in range(100):\n",
    "    nim = Nim(5)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    #logging.info(f\"status: Player {player} won!\")\n",
    "    score[player] += 1\n",
    "logging.info(f\"score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:score: [100, 0]\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "strategy = (gabriele, gabriele)\n",
    "\n",
    "score = [0, 0]\n",
    "for i in range(100):\n",
    "    nim = Nim(6)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    #logging.info(f\"status: Player {player} won!\")\n",
    "    score[player] += 1\n",
    "logging.info(f\"score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that if players choose the same strategies than they are equally likely to win except for gabriele where its is only the second player that win if the number of row is odd and the first one if the number of row is even (Which makes sense because you take all the objects of the smallest row so if both players plays like that the issue of the game is always the same and oonly depend on the number of rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Write an expert agent using Nim-Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "def nim_sum(state: Nim) -> int:\n",
    "    tmp = np.array([tuple(int(x) for x in f\"{c:032b}\") for c in state.rows])\n",
    "    # Create binary lines were the last bits are the number of objects in each row(written in binary)\n",
    "    xor = tmp.sum(axis=0) % 2\n",
    "    return int(\"\".join(str(_) for _ in xor), base=2)\n",
    "\n",
    "print(nim_sum(Nim(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_nim_agent(state: Nim) -> Nimply:\n",
    "    nim = nim_sum(state)\n",
    "    non_null = len([r for r in state.rows if r > 0])\n",
    "\n",
    "    # Case 1: There is only one row with objects, we take all the objects but one --> We win if the number of object >1\n",
    "    if non_null == 1:\n",
    "        max_row = max(state.rows)\n",
    "        row_index = state.rows.index(max_row)\n",
    "        return row_index, max_row - 1\n",
    "    \n",
    "    # Case 2: There is only 2 row with objects and one with only object in it, we take all the objects but one in the row with the maximum of object\n",
    "    # --> We win\n",
    "    if non_null == 2 and 1 in state.rows:\n",
    "        max_row = max(state.rows)\n",
    "        row_index = state.rows.index(max_row)\n",
    "        return row_index, max_row\n",
    "    \n",
    "    # Case 3: We are on a stable state : we make a little perturbation\n",
    "    if nim == 0:\n",
    "        max_row = max(state.rows)\n",
    "        row_index = state.rows.index(max_row)\n",
    "        return row_index, 1\n",
    "    \n",
    "    # Case 4: We are not in the stable state nut we can make it stable by removing some object\n",
    "    for i, row in enumerate(state.rows):\n",
    "        if row & nim ^ nim == 0:\n",
    "            return i, nim\n",
    "        \n",
    "    # Case 5: We are in non of the above cases : we are in loosing position. We make a random move\n",
    "    return pure_random(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:init : <1 3 5 7 9>\n",
      "INFO:root:ply: player 0 plays (4, 9)\n",
      "INFO:root:status: <1 3 5 7 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=2, num_objects=3)\n",
      "INFO:root:status: <1 3 2 7 0>\n",
      "INFO:root:ply: player 0 plays (3, 7)\n",
      "INFO:root:status: <1 3 2 0 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=1, num_objects=2)\n",
      "INFO:root:status: <1 1 2 0 0>\n",
      "INFO:root:ply: player 0 plays (2, 2)\n",
      "INFO:root:status: <1 1 0 0 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=0, num_objects=1)\n",
      "INFO:root:status: <0 1 0 0 0>\n",
      "INFO:root:ply: player 0 plays (1, 0)\n",
      "INFO:root:status: <0 1 0 0 0>\n",
      "INFO:root:ply: player 1 plays Nimply(row=1, num_objects=1)\n",
      "INFO:root:status: <0 0 0 0 0>\n",
      "INFO:root:status: Player 0 won!\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "strategy = (expert_nim_agent, pure_random)\n",
    "nim = Nim(5)\n",
    "logging.info(f\"init : {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    logging.info(f\"ply: player {player} plays {ply}\")\n",
    "    nim.nimming(ply)\n",
    "    logging.info(f\"status: {nim}\")\n",
    "    player = 1 - player\n",
    "logging.info(f\"status: Player {player} won!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:score: [100, 0]\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "strategy = (expert_nim_agent, pure_random)\n",
    "score = [0, 0]\n",
    "for i in range(100):\n",
    "    alea = random.randint(5, 20)\n",
    "    nim = Nim(alea)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    #logging.info(f\"status: Player {player} won!\")\n",
    "    score[player] += 1\n",
    "logging.info(f\"score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:score: [100, 0]\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "strategy = (expert_nim_agent, optimal)\n",
    "score = [0, 0]\n",
    "for i in range(100):\n",
    "    alea = random.randint(5, 20)\n",
    "    nim = Nim(alea)\n",
    "    #logging.info(f\"init : {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        #logging.info(f\"ply: player {player} plays {ply}\")\n",
    "        nim.nimming(ply)\n",
    "        #logging.info(f\"status: {nim}\")\n",
    "        player = 1 - player\n",
    "    #logging.info(f\"status: Player {player} won!\")\n",
    "    score[player] += 1\n",
    "logging.info(f\"score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the results are reaaly satisfying with this expert agent as we are always winning against optimal strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Write an agent using evolving rules using ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRATEGIES = [pure_random, gabriele, optimal, expert_nim_agent]\n",
    "NIM_DIM = 5\n",
    "MAX_NUMBER_MOVES = sum([i * 2 + 1 for i in range(NIM_DIM)])\n",
    "# expert agent -> each move is optimal move\n",
    "EXPERT_AGENT = [optimal] * MAX_NUMBER_MOVES\n",
    "FITNESS_MATCHES = 15\n",
    "POPULATION_SIZE = 20\n",
    "MUTATION_RATE = 0.1\n",
    "NUMBER_GENERATIONS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_agent(): \n",
    "    return [ random.choices(STRATEGIES)[0] for _ in range(MAX_NUMBER_MOVES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(agent1, agent2, n_row = 5):\n",
    "    strategy = (agent1, agent2) #agent2 = EXPERT_AGENT\n",
    "    nim = Nim(n_row)\n",
    "    player = random.randint(0, 1)\n",
    "    number_moves = 0\n",
    "    while nim:\n",
    "        ply = strategy[player][number_moves](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player\n",
    "        number_moves += 1\n",
    "    return player, number_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(agent):\n",
    "    results = [match(agent) for _ in range(FITNESS_MATCHES)]\n",
    "    return sum([res[0] for res in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(agent):\n",
    "    p = random.uniform(0,1)\n",
    "    if p<0.5:\n",
    "        swap_index1, swap_index2 = random.sample(range(MAX_NUMBER_MOVES), 2)\n",
    "        agent[swap_index1], agent[swap_index2] = (\n",
    "            agent[swap_index2],\n",
    "            agent[swap_index1],\n",
    "        )\n",
    "    else:\n",
    "        agent[random.randint(0, MAX_NUMBER_MOVES - 1)] = random.choice(STRATEGIES)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproduce(agent1, agent2):\n",
    "    agents = [agent1, agent2]\n",
    "    i = random.randint(0, 1)\n",
    "    split = random.randint(0, MAX_NUMBER_MOVES - 1)\n",
    "    return agents[i][:split] + agents[1-i][split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "population = [generate_random_agent() for _ in range(POPULATION_SIZE)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0 - Best Fitness: 14 - Avg Fitness: 6.85\n",
      "Generation 5 - Best Fitness: 15 - Avg Fitness: 10.5\n",
      "Generation 10 - Best Fitness: 14 - Avg Fitness: 11.7\n",
      "Generation 15 - Best Fitness: 14 - Avg Fitness: 11.1\n",
      "Generation 20 - Best Fitness: 15 - Avg Fitness: 11.4\n",
      "Generation 25 - Best Fitness: 14 - Avg Fitness: 11.75\n",
      "Generation 30 - Best Fitness: 14 - Avg Fitness: 10.95\n",
      "Generation 35 - Best Fitness: 15 - Avg Fitness: 11.5\n",
      "Generation 40 - Best Fitness: 13 - Avg Fitness: 10.55\n",
      "Generation 45 - Best Fitness: 14 - Avg Fitness: 11.7\n",
      "Generation 50 - Best Fitness: 15 - Avg Fitness: 11.7\n",
      "Generation 55 - Best Fitness: 14 - Avg Fitness: 11.2\n",
      "Generation 60 - Best Fitness: 14 - Avg Fitness: 10.65\n",
      "Generation 65 - Best Fitness: 15 - Avg Fitness: 11.3\n",
      "Generation 70 - Best Fitness: 14 - Avg Fitness: 11.6\n",
      "Generation 75 - Best Fitness: 14 - Avg Fitness: 11.65\n",
      "Generation 80 - Best Fitness: 15 - Avg Fitness: 11.3\n",
      "Generation 85 - Best Fitness: 14 - Avg Fitness: 11.05\n",
      "Generation 90 - Best Fitness: 13 - Avg Fitness: 10.65\n",
      "Generation 95 - Best Fitness: 15 - Avg Fitness: 10.1\n",
      "Generation 100 - Best Fitness: 13 - Avg Fitness: 9.05\n",
      "Generation 105 - Best Fitness: 12 - Avg Fitness: 8.35\n",
      "Generation 110 - Best Fitness: 12 - Avg Fitness: 8.65\n",
      "Generation 115 - Best Fitness: 13 - Avg Fitness: 8.75\n",
      "Generation 120 - Best Fitness: 13 - Avg Fitness: 8.5\n",
      "Generation 125 - Best Fitness: 13 - Avg Fitness: 9.0\n",
      "Generation 130 - Best Fitness: 13 - Avg Fitness: 8.1\n",
      "Generation 135 - Best Fitness: 12 - Avg Fitness: 7.05\n",
      "Generation 140 - Best Fitness: 9 - Avg Fitness: 4.6\n",
      "Generation 145 - Best Fitness: 10 - Avg Fitness: 4.4\n",
      "Generation 150 - Best Fitness: 10 - Avg Fitness: 5.85\n",
      "Generation 155 - Best Fitness: 11 - Avg Fitness: 6.2\n",
      "Generation 160 - Best Fitness: 14 - Avg Fitness: 7.9\n",
      "Generation 165 - Best Fitness: 10 - Avg Fitness: 7.3\n",
      "Generation 170 - Best Fitness: 10 - Avg Fitness: 7.1\n",
      "Generation 175 - Best Fitness: 9 - Avg Fitness: 6.45\n",
      "Generation 180 - Best Fitness: 12 - Avg Fitness: 9.3\n",
      "Generation 185 - Best Fitness: 13 - Avg Fitness: 8.4\n",
      "Generation 190 - Best Fitness: 13 - Avg Fitness: 10.35\n",
      "Generation 195 - Best Fitness: 13 - Avg Fitness: 10.5\n",
      "\n",
      "Best Agent -> ['pure_random', 'optimal', 'optimal', 'pure_random', 'gabriele', 'expert_nim_agent', 'gabriele', 'gabriele', 'optimal', 'pure_random', 'pure_random', 'gabriele', 'pure_random', 'optimal', 'pure_random', 'optimal', 'optimal', 'pure_random', 'gabriele', 'expert_nim_agent', 'gabriele', 'pure_random', 'optimal', 'optimal', 'gabriele']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_fitness(agent):\n",
    "\n",
    "    for generation in range(NUMBER_GENERATIONS):\n",
    "        fitness_scores = [fitness(agent) for agent in population]\n",
    "\n",
    "        if generation % 5 == 0:\n",
    "            max_fitness = max(fitness_scores)\n",
    "            print(\n",
    "                \"Generation\",\n",
    "                generation,\n",
    "                \"- Best Fitness:\",\n",
    "                max_fitness,\n",
    "                \"- Avg Fitness:\",\n",
    "                np.mean(fitness_scores),\n",
    "            )\n",
    "\n",
    "        # next gen parents\n",
    "        selected_parents = random.choices(\n",
    "            population, weights=fitness_scores, k=POPULATION_SIZE // 3\n",
    "        )\n",
    "\n",
    "        # create next gen\n",
    "        new_population = []\n",
    "        for i in range(POPULATION_SIZE):\n",
    "            if random.random() < MUTATION_RATE:\n",
    "                new_population.append(mutate(random.choice(selected_parents)))\n",
    "            else:\n",
    "                agent1 = random.choice(selected_parents)\n",
    "                agent2 = random.choice(selected_parents)\n",
    "                new_population.append(reproduce(agent1, agent2))\n",
    "\n",
    "        population = new_population\n",
    "\n",
    "    # print best agent\n",
    "    best_agent = max(population, key=fitness)\n",
    "    print()\n",
    "    print(\"Best Agent ->\", [strat.__name__ for strat in best_agent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!FINAL BOSS!\n",
      "1000 matches VS EXPERT AGENT\n",
      "Evolved Agent -> 681 won!\n",
      "Random Agent  -> 468 won!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expert_nim_agent() missing 1 required positional argument: 'state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb Cellule 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mEvolved Agent ->\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39msum\u001b[39m([match(best_agent)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m)]),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwon!\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRandom Agent  ->\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39msum\u001b[39m([match(generate_random_agent())[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m)]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwon!\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mExpert agent  ->\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39msum\u001b[39m([match(expert_nim_agent()) \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m1000\u001b[39;49m)]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwon!\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb Cellule 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mEvolved Agent ->\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39msum\u001b[39m([match(best_agent)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m)]),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwon!\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRandom Agent  ->\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39msum\u001b[39m([match(generate_random_agent())[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m)]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwon!\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mExpert agent  ->\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39msum\u001b[39m([match(expert_nim_agent()) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1000\u001b[39m)]),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwon!\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/roxane/Documents/GitHub/Computational-intelligence/Lab2/lab2-nim.ipynb#X64sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: expert_nim_agent() missing 1 required positional argument: 'state'"
     ]
    }
   ],
   "source": [
    "print(\"!FINAL BOSS!\\n1000 matches VS EXPERT AGENT\") # 30ish secs on i5\n",
    "# if around 500 its basically as good as EXPERT AGENT\n",
    "print(\n",
    "    \"Evolved Agent ->\",\n",
    "    sum([match(best_agent)[0] for _ in range(1000)]),\n",
    "    \"won!\",\n",
    ")\n",
    "\n",
    "\n",
    "print(\n",
    "    \"Random Agent  ->\",\n",
    "    sum([match(generate_random_agent())[0] for _ in range(1000)]),\n",
    "    \"won!\",\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('ci22-dPIXJ0_o-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "10197e8e2f2aa67e2c349105091c77f4cd384fce4877865f002d9ec653f96bc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
